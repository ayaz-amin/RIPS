{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RIPS 001 \"STRANGE MATTER\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaRQl0Bk1HFn",
        "outputId": "74f6ce99-ac60-4109-855f-35998b933b75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Reward Induced Program Synthesis - RIPS 001 \"STRANGE MATTER\"\n",
        "!pip install git+https://github.com/ayaz-amin/schema-rl.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ayaz-amin/schema-rl.git\n",
            "  Cloning https://github.com/ayaz-amin/schema-rl.git to /tmp/pip-req-build-uggcn25v\n",
            "  Running command git clone -q https://github.com/ayaz-amin/schema-rl.git /tmp/pip-req-build-uggcn25v\n",
            "Requirement already satisfied: gym>=0.9.1[all] in /usr/local/lib/python3.6/dist-packages (from schema-games==1.0.0) (0.17.3)\n",
            "Collecting pygame\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/4c/2ebe8ab1a695a446574bc48d96eb3503649893be8c769e7fafd65fd18833/pygame-2.0.0-cp36-cp36m-manylinux1_x86_64.whl (11.5MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5MB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from schema-games==1.0.0) (3.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from schema-games==1.0.0) (0.16.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.9.1[all]->schema-games==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym>=0.9.1[all]->schema-games==1.0.0) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym>=0.9.1[all]->schema-games==1.0.0) (1.18.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.9.1[all]->schema-games==1.0.0) (1.5.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->schema-games==1.0.0) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->schema-games==1.0.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->schema-games==1.0.0) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->schema-games==1.0.0) (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->schema-games==1.0.0) (1.15.0)\n",
            "Building wheels for collected packages: schema-games\n",
            "  Building wheel for schema-games (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for schema-games: filename=schema_games-1.0.0-cp36-none-any.whl size=28598 sha256=306346abdec71bf0734721177c98da32e2824049de0d21ee46062651cb315366\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4beobeub/wheels/4a/fe/a0/6800016926ff46b11b889e96271961e5c5947e7f7e67c99435\n",
            "Successfully built schema-games\n",
            "Installing collected packages: pygame, schema-games\n",
            "Successfully installed pygame-2.0.0 schema-games-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mQ-DfOn1pNt"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.distributions as dist\n",
        "\n",
        "\n",
        "class EntityExtractor(nn.Module):\n",
        "    def __init__(self, input_channels, num_objects):\n",
        "        super(EntityExtractor, self).__init__()\n",
        "\n",
        "        self.input_channels = input_channels\n",
        "        self.filters = nn.Sequential(\n",
        "                nn.Conv2d(input_channels, 32, kernel_size=3, padding=1),\n",
        "                nn.ReLU(True),\n",
        "                nn.MaxPool2d((2, 2)),\n",
        "                nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "                nn.ReLU(True),\n",
        "                nn.MaxPool2d((2, 2)),\n",
        "                nn.Conv2d(64, num_objects, kernel_size=1),\n",
        "                nn.Sigmoid()\n",
        "                )\n",
        "\n",
        "    def obs_to_torch(self, obs):\n",
        "        height, width = obs.shape[0], obs.shape[1]\n",
        "        obs = torch.from_numpy(obs.copy()).float()\n",
        "        return obs.view(1, self.input_channels, height, width)\n",
        "\n",
        "    def parsed_objects(self, z):\n",
        "        object_blackboard = torch.zeros(z.shape[2], z.shape[3])\n",
        "        \n",
        "        z = z.view(z.shape[1], z.shape[2], z.shape[3])\n",
        "        for object_idx in range(z.shape[0]):\n",
        "            for r in range(z.shape[1]):\n",
        "                for c in range(z.shape[2]):\n",
        "                    if z[object_idx, r, c] != 0:\n",
        "                        object_blackboard[r][c] = object_idx\n",
        "\n",
        "        return object_blackboard.detach().numpy()\n",
        "\n",
        "    def forward(self, obs):\n",
        "        obs = self.obs_to_torch(obs)\n",
        "        z = self.filters(obs)\n",
        "        return self.parsed_objects(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ7z5PJH1vya"
      },
      "source": [
        "def out_of_bounds(r, c, shape):\n",
        "    return (r < 0 or c < 0 or r >= shape[0] or c >= shape[1])\n",
        "\n",
        "def shifted(direction, local_program, cell, obs):\n",
        "    if cell is None:\n",
        "        new_cell = None\n",
        "    else:\n",
        "        new_cell = (cell[0] + direction[0], cell[1] + direction[1])\n",
        "    return local_program(new_cell, obs)\n",
        "\n",
        "def cell_is_value(value, cell, obs):\n",
        "    if cell is None or out_of_bounds(cell[0], cell[1], obs.shape):\n",
        "        focus = None\n",
        "    else:\n",
        "        focus = obs[cell[0], cell[1]]\n",
        "\n",
        "    return (focus == value)\n",
        "\n",
        "def at_cell_with_value(value, local_program, obs):\n",
        "    matches = np.argwhere(obs == value)\n",
        "    if len(matches) == 0:\n",
        "        cell = None\n",
        "    else:\n",
        "        cell = matches[0]\n",
        "    return local_program(cell, obs)\n",
        "\n",
        "def scanning(direction, true_condition, false_condition, cell, obs, max_timeout=50):\n",
        "    if cell is None:\n",
        "        return False\n",
        "\n",
        "    for _ in range(max_timeout):\n",
        "        cell = (cell[0] + direction[0], cell[1] + direction[1])\n",
        "\n",
        "        if true_condition(cell, obs):\n",
        "            return True\n",
        "\n",
        "        if false_condition(cell, obs):\n",
        "            return False\n",
        "\n",
        "        # prevent infinite loops\n",
        "        if out_of_bounds(cell[0], cell[1], obs.shape):\n",
        "            return False\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "# My classes\n",
        "class Model(nn.Module):\n",
        "    # Container for program synthesis model\n",
        "    def __init__(self, input_channels, object_types, action_types, num_programs):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.feature_extractor = EntityExtractor(input_channels, object_types)\n",
        "        self.action_types = action_types\n",
        "        self.programs = nn.ModuleList()\n",
        "        for i in range(num_programs):\n",
        "            self.programs.append(AtActionCell(object_types, action_types))\n",
        "\n",
        "    def forward(self, obs):\n",
        "        obs = self.feature_extractor(obs)\n",
        "        action_probs = torch.zeros(self.action_types)\n",
        "        for r in range(obs.shape[0]):\n",
        "            for c in range(obs.shape[1]):\n",
        "                for program in self.programs:\n",
        "                    condition, action = program((r, c), obs)\n",
        "                    if condition:\n",
        "                        action_probs[action] += 1\n",
        "\n",
        "        normalized_action_probs = F.log_softmax(action_probs, dim=0)\n",
        "        return dist.Categorical(normalized_action_probs) \n",
        "\n",
        "\n",
        "class AtActionCell(nn.Module):\n",
        "    def __init__(self, object_types, action_types):\n",
        "        super(AtActionCell, self).__init__()\n",
        "        self.object_types = nn.Parameter(torch.ones(object_types))\n",
        "        self.positive_object_types = nn.Parameter(torch.ones(object_types))\n",
        "        self.negative_object_types = nn.Parameter(torch.ones(object_types))\n",
        "\n",
        "        self.action_types = nn.Parameter(torch.ones(action_types))\n",
        "        self.direction_types = nn.Parameter(torch.ones(8))\n",
        "        self.directions = [\n",
        "            (1, 0), (0, 1),\n",
        "            (-1, 0), (0, -1),\n",
        "            (1, 1), (-1, 1),\n",
        "            (1, -1), (-1, -1)\n",
        "        ]\n",
        "\n",
        "    def forward(self, cell, obs):\n",
        "        # Sample function parameters\n",
        "        object_probs = F.log_softmax(self.object_types, dim=0)\n",
        "        positive_object_probs = F.log_softmax(self.positive_object_types, dim=0)\n",
        "        negative_object_probs = F.log_softmax(self.negative_object_types, dim=0)\n",
        "\n",
        "        action_probs = F.log_softmax(self.action_types, dim=0)\n",
        "        direction_probs = F.log_softmax(self.direction_types, dim=0)\n",
        "\n",
        "        sample_object = dist.Categorical(object_probs).sample()\n",
        "        sample_positive_object = dist.Categorical(positive_object_probs).sample()\n",
        "        sample_negative_object = dist.Categorical(negative_object_probs).sample()\n",
        "\n",
        "        sample_action = dist.Categorical(action_probs).sample()\n",
        "        sample_direction = dist.Categorical(direction_probs).sample()\n",
        "\n",
        "        direction = self.directions[sample_direction]\n",
        "\n",
        "        # Main program\n",
        "        condition = at_cell_with_value(\n",
        "            sample_object, \n",
        "            lambda cell, obs : scanning(\n",
        "                direction,\n",
        "                lambda cell, obs : cell_is_value(sample_positive_object, cell, obs),\n",
        "                lambda cell, obs : cell_is_value(sample_negative_object, cell, obs),\n",
        "                cell,\n",
        "                obs\n",
        "            ),\n",
        "            obs\n",
        "        )\n",
        "\n",
        "        return condition, sample_action"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIV9gdRO13J3",
        "outputId": "e0441244-e4b1-4b8b-864f-161f3f5ae888",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "from gym.wrappers import Monitor\n",
        "from schema_games.breakout.games import StandardBreakout\n",
        "\n",
        "model = Model(input_channels=3, object_types=5, action_types=3, num_programs=10)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "env = Monitor(StandardBreakout(return_state_as_image=True), 'video', force=True)\n",
        "\n",
        "for epoch in range(10):\n",
        "    obs = env.reset()\n",
        "    loss = []\n",
        "    while True:\n",
        "        env.render()\n",
        "        action_probs = model(obs)\n",
        "        action = action_probs.sample()\n",
        "        #action = env.action_space.sample()\n",
        "        obs, reward, done, _ = env.step(action.item())\n",
        "        loss.append(-action_probs.log_prob(action) * reward)\n",
        "        if done:\n",
        "            optimizer.zero_grad()\n",
        "            loss = torch.tensor(sum(loss), requires_grad=True) / len(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            print(loss)\n",
        "            loss = []\n",
        "            break\n",
        "\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Trying to monitor an environment which has no 'spec' set. This usually means you did not create it via 'gym.make', and is recommended only for advanced users.\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m[---] Lives remaining:\u001b[0m 2\n",
            "\u001b[31m[---] Lives remaining:\u001b[0m 1\n",
            "\u001b[31m[---] Game over! You lost.\u001b[0m\n",
            "\u001b[31m********************************************************************************\u001b[0m\n",
            "tensor(-0.0062, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m[---] Lives remaining:\u001b[0m 2\n",
            "\u001b[31m[---] Lives remaining:\u001b[0m 1\n",
            "\u001b[31m[---] Game over! You lost.\u001b[0m\n",
            "\u001b[31m********************************************************************************\u001b[0m\n",
            "tensor(-0.0188, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m[---] Lives remaining:\u001b[0m 2\n",
            "\u001b[31m[---] Lives remaining:\u001b[0m 1\n",
            "\u001b[31m[---] Game over! You lost.\u001b[0m\n",
            "\u001b[31m********************************************************************************\u001b[0m\n",
            "tensor(0., grad_fn=<DivBackward0>)\n",
            "\u001b[31m[---] Lives remaining:\u001b[0m 2\n",
            "\u001b[31m[---] Lives remaining:\u001b[0m 1\n",
            "\u001b[31m[---] Game over! You lost.\u001b[0m\n",
            "\u001b[31m********************************************************************************\u001b[0m\n",
            "tensor(-0.0578, grad_fn=<DivBackward0>)\n",
            "\u001b[31m[---] Lives remaining:\u001b[0m 2\n",
            "\u001b[31m[---] Lives remaining:\u001b[0m 1\n",
            "\u001b[31m[---] Game over! You lost.\u001b[0m\n",
            "\u001b[31m********************************************************************************\u001b[0m\n",
            "tensor(-0.0035, grad_fn=<DivBackward0>)\n",
            "\u001b[31m[---] Lives remaining:\u001b[0m 2\n",
            "\u001b[31m[---] Lives remaining:\u001b[0m 1\n",
            "\u001b[31m[---] Game over! You lost.\u001b[0m\n",
            "\u001b[31m********************************************************************************\u001b[0m\n",
            "tensor(0.0060, grad_fn=<DivBackward0>)\n",
            "\u001b[31m[---] Lives remaining:\u001b[0m 2\n",
            "\u001b[31m[---] Lives remaining:\u001b[0m 1\n",
            "\u001b[31m[---] Game over! You lost.\u001b[0m\n",
            "\u001b[31m********************************************************************************\u001b[0m\n",
            "tensor(-0.0578, grad_fn=<DivBackward0>)\n",
            "\u001b[31m[---] Lives remaining:\u001b[0m 2\n",
            "\u001b[31m[---] Lives remaining:\u001b[0m 1\n",
            "\u001b[31m[---] Game over! You lost.\u001b[0m\n",
            "\u001b[31m********************************************************************************\u001b[0m\n",
            "tensor(-0.0188, grad_fn=<DivBackward0>)\n",
            "\u001b[31m[---] Lives remaining:\u001b[0m 2\n",
            "\u001b[31m[---] Lives remaining:\u001b[0m 1\n",
            "\u001b[31m[---] Game over! You lost.\u001b[0m\n",
            "\u001b[31m********************************************************************************\u001b[0m\n",
            "tensor(-0.0045, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m[---] Lives remaining:\u001b[0m 2\n",
            "\u001b[31m[---] Lives remaining:\u001b[0m 1\n",
            "\u001b[31m[---] Game over! You lost.\u001b[0m\n",
            "\u001b[31m********************************************************************************\u001b[0m\n",
            "tensor(-0.0062, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDB0LzOx5zg-",
        "outputId": "bdbdf98c-b972-4598-efc7-4b908854a53b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "video = io.open('video/openaigym.video.%s.video000000.mp4' % env.file_infix, 'r+b').read()\n",
        "encoded = base64.b64encode(video)\n",
        "HTML(data='''\n",
        "    <video width=\"54\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>'''\n",
        ".format(encoded.decode('ascii')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <video width=\"54\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" /></video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AGdic1UCIUZ"
      },
      "source": [
        "torch.save(model.state_dict(), 'rips_sidereal.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}