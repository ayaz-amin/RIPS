{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RIPS 001 \"DOPPLER\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaRQl0Bk1HFn",
        "outputId": "036a54a4-33d2-4a41-f952-e1b21a072c11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "## Development for this pretty much halted since this version of the project is slow AF. Each step\n",
        "## of the environment takes at least one minute to perform even on a GPU due to the large enumeration\n",
        "## space over the cells of the observation. Contiuation of this project is being done on the second version of RIPS.\n",
        "## Codenamed \"STRANGE MATTER\", this variant is much faster since convolutional filters are used to decrease the dimensions of the input space.\n",
        "\n",
        "# Reward Induced Program Synthesis - RIPS 001 \"DOPPLER\"\n",
        "!pip install git+https://github.com/ayaz-amin/schema-rl.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ayaz-amin/schema-rl.git\n",
            "  Cloning https://github.com/ayaz-amin/schema-rl.git to /tmp/pip-req-build-7cum3xdo\n",
            "  Running command git clone -q https://github.com/ayaz-amin/schema-rl.git /tmp/pip-req-build-7cum3xdo\n",
            "Requirement already satisfied: gym>=0.9.1[all] in /usr/local/lib/python3.6/dist-packages (from schema-games==1.0.0) (0.17.2)\n",
            "Collecting pygame\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/ede6428359f913ed9cd1643dd5533aefeb5a2699cc95bea089de50ead586/pygame-1.9.6-cp36-cp36m-manylinux1_x86_64.whl (11.4MB)\n",
            "\u001b[K     |████████████████████████████████| 11.4MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from schema-games==1.0.0) (3.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from schema-games==1.0.0) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym>=0.9.1[all]->schema-games==1.0.0) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym>=0.9.1[all]->schema-games==1.0.0) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.9.1[all]->schema-games==1.0.0) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.9.1[all]->schema-games==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->schema-games==1.0.0) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->schema-games==1.0.0) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->schema-games==1.0.0) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->schema-games==1.0.0) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->schema-games==1.0.0) (1.15.0)\n",
            "Building wheels for collected packages: schema-games\n",
            "  Building wheel for schema-games (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for schema-games: filename=schema_games-1.0.0-cp36-none-any.whl size=28598 sha256=b78c31991de690cadac6a43a110c2c241ab3bbcd5703415b6d1f25ba66dfd849\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d_ujtdql/wheels/4a/fe/a0/6800016926ff46b11b889e96271961e5c5947e7f7e67c99435\n",
            "Successfully built schema-games\n",
            "Installing collected packages: pygame, schema-games\n",
            "Successfully installed pygame-1.9.6 schema-games-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbKGO_1Z1eTC"
      },
      "source": [
        "# Ripped off from https://github.com/cog-isa/schema-rl/\n",
        "\n",
        "from schema_games.breakout.constants import \\\n",
        "    BRICK_SIZE, ENV_SIZE, DEFAULT_HEIGHT, DEFAULT_WIDTH, DEFAULT_PADDLE_SHAPE\n",
        "\n",
        "\n",
        "class Constants:\n",
        "    \"\"\"\n",
        "    N: number of entities\n",
        "    M: number of attributes of each entity\n",
        "    A: number of available actions\n",
        "    L: number of schemas\n",
        "    T: size of look-ahead window\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Agent options ---\n",
        "\n",
        "    DO_PRELOAD_DUMP_PARAMS = False\n",
        "\n",
        "    DO_PRELOAD_HANDCRAFTED_ATTRIBUTE_PARAMS = False\n",
        "    DO_PRELOAD_HANDCRAFTED_REWARD_PARAMS = False\n",
        "\n",
        "    DO_LEARN_ATTRIBUTE_PARAMS = True\n",
        "    DO_LEARN_REWARD_PARAMS = True\n",
        "\n",
        "    # planning options are ('agent', 'hardcoded', 'random')\n",
        "    PLANNING_TYPE = 'agent'\n",
        "\n",
        "    LEARNING_PERIOD = 128\n",
        "    LEARNING_SOLVER = 'cbc'  # 'cbc', 'gurobi'\n",
        "    USE_EMERGENCY_PLANNING = True\n",
        "\n",
        "    VISUALIZE_STATE = True\n",
        "    VISUALIZE_SCHEMAS = False\n",
        "    VISUALIZE_INNER_STATE = True\n",
        "    VISUALIZE_BACKTRACKING = True\n",
        "    LOG_PLANNED_ACTIONS = False\n",
        "\n",
        "    N_LEARNING_THREADS = 16\n",
        "\n",
        "    L = 1000\n",
        "    NEIGHBORHOOD_RADIUS = 2\n",
        "\n",
        "    if ENV_SIZE == 'SMALL':\n",
        "        # T = 112 is enough to hit the furthest brick\n",
        "        # EMERG_PERIOD = 15 is enough to plan with ball being near closest brick\n",
        "        T = 112  # min 50\n",
        "        PLANNING_PERIOD = 10  # run planning every *this* steps\n",
        "        EMERGENCY_PLANNING_PERIOD = 10  # run planning every *this* steps if there are no planned actions\n",
        "    elif ENV_SIZE == 'DEFAULT':\n",
        "        T = 130  # min 112\n",
        "        PLANNING_PERIOD = 10\n",
        "        EMERGENCY_PLANNING_PERIOD = 30\n",
        "    else:\n",
        "        assert False\n",
        "\n",
        "    # --- Constants ---\n",
        "\n",
        "    LEARNING_SCHEMA_TOLERANCE = 1e-8\n",
        "    ADDING_SCHEMA_TOLERANCE = 1e-8\n",
        "\n",
        "    SCREEN_HEIGHT = DEFAULT_HEIGHT\n",
        "    SCREEN_WIDTH = DEFAULT_WIDTH\n",
        "    N = SCREEN_WIDTH * SCREEN_HEIGHT\n",
        "    M = 5\n",
        "    N_PREDICTABLE_ATTRIBUTES = M - 1\n",
        "    ACTION_SPACE_DIM = 3\n",
        "    REWARD_SPACE_DIM = 2\n",
        "\n",
        "    FILTER_SIZE = 2 * NEIGHBORHOOD_RADIUS + 1\n",
        "    NEIGHBORS_NUM = FILTER_SIZE ** 2 - 1\n",
        "    FRAME_STACK_SIZE = 2\n",
        "    SCHEMA_VEC_SIZE = FRAME_STACK_SIZE * (M * (NEIGHBORS_NUM + 1)) + ACTION_SPACE_DIM\n",
        "    TIME_SIZE = FRAME_STACK_SIZE + T\n",
        "    LEARNING_BATCH_SIZE = FRAME_STACK_SIZE + 1\n",
        "\n",
        "    # indices of corresponding attributes in entities' vectors\n",
        "    BALL_IDX = 0\n",
        "    PADDLE_IDX = 1\n",
        "    WALL_IDX = 2\n",
        "    BRICK_IDX = 3\n",
        "    VOID_IDX = 4\n",
        "    FAKE_ENTITY_IDX = N\n",
        "\n",
        "    # action indices\n",
        "    ACTION_NOP = 0\n",
        "    ACTION_MOVE_LEFT = 1\n",
        "    ACTION_MOVE_RIGHT = 2\n",
        "\n",
        "    ENTITY_NAMES = {\n",
        "        BALL_IDX: 'BALL',\n",
        "        PADDLE_IDX: 'PADDLE',\n",
        "        WALL_IDX: 'WALL',\n",
        "        BRICK_IDX: 'BRICK',\n",
        "    }\n",
        "\n",
        "    REWARD_NAMES = {\n",
        "        0: 'POSITIVE',\n",
        "        1: 'NEGATIVE',\n",
        "    }\n",
        "\n",
        "    ATTRIBUTE = 'attribute'\n",
        "    REWARD = 'reward'\n",
        "    ALLOWED_OBJ_TYPES = {ATTRIBUTE, REWARD}\n",
        "\n",
        "    DEFAULT_PADDLE_SHAPE = DEFAULT_PADDLE_SHAPE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mQ-DfOn1pNt"
      },
      "source": [
        "# Ripped off from https://github.com/cog-isa/schema-rl/\n",
        "class EntityExtractor(Constants):\n",
        "    @classmethod\n",
        "    def extract(cls, env):\n",
        "        \"\"\"\n",
        "        :param env: object, child of BreakoutEngine\n",
        "        \"\"\"\n",
        "        matrix = np.zeros((cls.N, cls.M), dtype=int)\n",
        "\n",
        "        for ball in env.balls:\n",
        "            if ball.is_entity:\n",
        "                for state, eid in env.parse_object_into_pixels(ball):\n",
        "                    idx = cls.get_entity_idx(state)\n",
        "                    matrix[idx][cls.BALL_IDX] = 0\n",
        "\n",
        "        if env.paddle.is_entity:\n",
        "            for state, eid in env.parse_object_into_pixels(env.paddle):\n",
        "                idx = cls.get_entity_idx(state)\n",
        "                matrix[idx][cls.PADDLE_IDX] = 1\n",
        "\n",
        "        for wall in env.walls:\n",
        "            if wall.is_entity:\n",
        "                for state, eid in env.parse_object_into_pixels(wall):\n",
        "                    idx = cls.get_entity_idx(state)\n",
        "                    matrix[idx][cls.WALL_IDX] = 2\n",
        "\n",
        "        for brick in env.bricks:\n",
        "            if brick.is_entity:\n",
        "                for state, eid in env.parse_object_into_pixels(brick):\n",
        "                    idx = cls.get_entity_idx(state)\n",
        "                    matrix[idx][cls.BRICK_IDX] = 3\n",
        "\n",
        "        # raise VOID bit\n",
        "        void_mask = ~matrix.any(axis=1)\n",
        "        matrix[void_mask, cls.VOID_IDX] = -1\n",
        "        matrix = matrix.reshape(cls.M, cls.SCREEN_WIDTH, cls.SCREEN_HEIGHT)\n",
        "        return matrix.max(0)\n",
        "\n",
        "    @classmethod\n",
        "    def transform_pos_to_index(cls, pos):\n",
        "        return pos[0] * cls.SCREEN_WIDTH + pos[1]\n",
        "\n",
        "    @classmethod\n",
        "    def get_entity_pos(cls, state):\n",
        "        return [*state][0][1]\n",
        "\n",
        "    @classmethod\n",
        "    def get_entity_idx(cls, state):\n",
        "        pos = cls.get_entity_pos(state)\n",
        "        idx = cls.transform_pos_to_index(pos)\n",
        "        return idx\n",
        "\n",
        "    @classmethod\n",
        "    def get_ball_x(cls, env):\n",
        "        for ball in env.balls:\n",
        "            if ball.is_entity:\n",
        "                for state, eid in env.parse_object_into_pixels(ball):\n",
        "                    pos = cls.get_entity_pos(state)\n",
        "                    return pos[1]\n",
        "    @classmethod\n",
        "    def get_paddle_keypoints(cls, env):\n",
        "        if env.paddle.is_entity:\n",
        "            pixels = env.parse_object_into_pixels(env.paddle)\n",
        "\n",
        "            mid_state, eid = pixels[len(pixels) // 2]\n",
        "            mid_pos = cls.get_entity_pos(mid_state)\n",
        "            mid = mid_pos[1]\n",
        "            offset = cls.DEFAULT_PADDLE_SHAPE[0] // 2\n",
        "\n",
        "            left = mid - offset + 1\n",
        "            right = mid + offset - 1\n",
        "\n",
        "            soft_left = left + 1\n",
        "            soft_right = right - 1\n",
        "\n",
        "\n",
        "            return left, mid, right, soft_left, soft_right, right, left, left, right"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ7z5PJH1vya"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.distributions as dist\n",
        "\n",
        "def out_of_bounds(r, c, shape):\n",
        "    return (r < 0 or c < 0 or r >= shape[0] or c >= shape[1])\n",
        "\n",
        "def shifted(direction, local_program, cell, obs):\n",
        "    if cell is None:\n",
        "        new_cell = None\n",
        "    else:\n",
        "        new_cell = (cell[0] + direction[0], cell[1] + direction[1])\n",
        "    return local_program(new_cell, obs)\n",
        "\n",
        "def cell_is_value(value, cell, obs):\n",
        "    if cell is None or out_of_bounds(cell[0], cell[1], obs.shape):\n",
        "        focus = None\n",
        "    else:\n",
        "        focus = obs[cell[0], cell[1]]\n",
        "\n",
        "    return (focus == value)\n",
        "\n",
        "def at_cell_with_value(value, local_program, obs):\n",
        "    matches = np.argwhere(obs == value)\n",
        "    if len(matches) == 0:\n",
        "        cell = None\n",
        "    else:\n",
        "        cell = matches[0]\n",
        "    return local_program(cell, obs)\n",
        "\n",
        "def scanning(direction, true_condition, false_condition, cell, obs, max_timeout=50):\n",
        "    if cell is None:\n",
        "        return False\n",
        "\n",
        "    for _ in range(max_timeout):\n",
        "        cell = (cell[0] + direction[0], cell[1] + direction[1])\n",
        "\n",
        "        if true_condition(cell, obs):\n",
        "            return True\n",
        "\n",
        "        if false_condition(cell, obs):\n",
        "            return False\n",
        "\n",
        "        # prevent infinite loops\n",
        "        if out_of_bounds(cell[0], cell[1], obs.shape):\n",
        "            return False\n",
        "\n",
        "    return False\n",
        "\n",
        "# My classes\n",
        "class Model(nn.Module):\n",
        "    # Container for program synthesis model\n",
        "    def __init__(self, object_types, action_types, num_programs):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.feature_extractor = EntityExtractor()\n",
        "        self.action_types = action_types\n",
        "        self.programs = nn.ModuleList()\n",
        "        for i in range(num_programs):\n",
        "            self.programs.append(AtActionCell(object_types, action_types))\n",
        "\n",
        "    def forward(self, env):\n",
        "        obs = self.feature_extractor.extract(env)\n",
        "        action_probs = torch.zeros(self.action_types)\n",
        "        for r in range(obs.shape[0]):\n",
        "            for c in range(obs.shape[1]):\n",
        "                for program in self.programs:\n",
        "                    condition, action = program((r, c), obs)\n",
        "                    if condition:\n",
        "                        action_probs[action] += 1\n",
        "\n",
        "        return dist.Categorical(F.log_softmax(action_probs, dim=0))\n",
        "\n",
        "\n",
        "class AtActionCell(nn.Module):\n",
        "    def __init__(self, object_types, action_types):\n",
        "        super(AtActionCell, self).__init__()\n",
        "        self.object_types = nn.Parameter(torch.ones(object_types))\n",
        "        self.positive_object_types = nn.Parameter(torch.ones(object_types))\n",
        "        self.negative_object_types = nn.Parameter(torch.ones(object_types))\n",
        "\n",
        "        self.action_types = nn.Parameter(torch.ones(action_types))\n",
        "        self.direction_types = nn.Parameter(torch.ones(8))\n",
        "        self.directions = [\n",
        "            (1, 0), (0, 1),\n",
        "            (-1, 0), (0, -1),\n",
        "            (1, 1), (-1, 1),\n",
        "            (1, -1), (-1, -1)\n",
        "        ]\n",
        "\n",
        "    def forward(self, cell, obs):\n",
        "        # Sample function parameters\n",
        "        object_probs = F.log_softmax(self.object_types, dim=0)\n",
        "        positive_object_probs = F.log_softmax(self.positive_object_types, dim=0)\n",
        "        negative_object_probs = F.log_softmax(self.negative_object_types, dim=0)\n",
        "\n",
        "        action_probs = F.log_softmax(self.action_types, dim=0)\n",
        "        direction_probs = F.log_softmax(self.direction_types, dim=0)\n",
        "\n",
        "        sample_object = dist.Categorical(object_probs).sample()\n",
        "        sample_positive_object = dist.Categorical(positive_object_probs).sample()\n",
        "        sample_negative_object = dist.Categorical(negative_object_probs).sample()\n",
        "\n",
        "        sample_action = dist.Categorical(action_probs).sample()\n",
        "        sample_direction = dist.Categorical(direction_probs).sample()\n",
        "\n",
        "        direction = self.directions[sample_direction]\n",
        "\n",
        "        # Main program\n",
        "        condition = at_cell_with_value(\n",
        "            sample_object, \n",
        "            lambda cell, obs : scanning(\n",
        "                direction,\n",
        "                lambda cell, obs : cell_is_value(sample_positive_object, cell, obs),\n",
        "                lambda cell, obs : cell_is_value(sample_negative_object, cell, obs),\n",
        "                cell,\n",
        "                obs\n",
        "            ),\n",
        "            obs\n",
        "        )\n",
        "\n",
        "        return condition, sample_action"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIV9gdRO13J3",
        "outputId": "36a46dd0-aee5-4258-c526-e4a17c260f79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "from gym.wrappers import Monitor\n",
        "from schema_games.breakout.games import StandardBreakout\n",
        "\n",
        "model = Model(object_types=5, action_types=3, num_programs=10).cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "env = Monitor(StandardBreakout(), 'video', force=True)\n",
        "\n",
        "obs = env.reset()\n",
        "\n",
        "for epoch in range(10):\n",
        "    steps = 0\n",
        "    loss = 0\n",
        "    while True:\n",
        "        steps += 1\n",
        "        env.render()\n",
        "        action_probs = model(env)\n",
        "        action = action_probs.sample()\n",
        "        #action = env.action_space.sample()\n",
        "        obs, reward, done, _ = env.step(action.item())\n",
        "        total_reward += reward\n",
        "        loss += -action_probs.log_prob(action) * reward\n",
        "        if done:\n",
        "            optimizer.zero_grad()\n",
        "            loss = loss / steps\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            print(loss)\n",
        "            break\n",
        "\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Trying to monitor an environment which has no 'spec' set. This usually means you did not create it via 'gym.make', and is recommended only for advanced users.\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m[---] Lives remaining:\u001b[0m 2\n",
            "\u001b[31m[---] Lives remaining:\u001b[0m 1\n",
            "\u001b[31m[---] Game over! You lost.\u001b[0m\n",
            "\u001b[31m********************************************************************************\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e10e97c40ad0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDB0LzOx5zg-",
        "outputId": "b6b7b1da-432f-4baa-e4ff-fea7ced4ef9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "env.close()\n",
        "\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "video = io.open('video/openaigym.video.%s.video000000.mp4' % env.file_infix, 'r+b').read()\n",
        "encoded = base64.b64encode(video)\n",
        "HTML(data='''\n",
        "    <video width=\"54\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>'''\n",
        ".format(encoded.decode('ascii')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <video width=\"54\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" /></video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AGdic1UCIUZ"
      },
      "source": [
        "torch.save(model.state_dict(), 'rips_sidereal.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
